{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c92590d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an agent which can get through a maze\n",
    "# It should have appropriate functions for learning,choosing actions,and updating its memory.\n",
    "\n",
    "# Create a class named agent add a function called learn, memory and actions\n",
    "# hasty first attempt\n",
    "# class Agent:\n",
    "#     def __init__(self, name, action, stateHistory):\n",
    "#         self.name = name\n",
    "#         self.action = action\n",
    "#         self.stateHistory = {action}\n",
    "\n",
    "# formatted with black\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Agent(object):\n",
    "    \"\"\"This is entity that learns and takes actions to maximize the reward.\n",
    "    Will track its state, make actions and finally make a decision.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, states, alpha):\n",
    "        self.stateHistory = None  # will be list of states and rewards\n",
    "        self.alpha = alpha\n",
    "        self.G = (\n",
    "            {}\n",
    "        )  # keys will be the states and values estimates of the future rewards.\n",
    "        self.initReward(states)\n",
    "\n",
    "    def initReward(self, states):\n",
    "        \"\"\"Initialize the state of rewards: Goes through each state in a dict.\n",
    "        Uses a uniform/binomial distribution\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        states : what has changed that is, the robot position. It ranges\n",
    "        between -0.1 and -1.0.\n",
    "            \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Int64 that is the state of our agent.\n",
    "\n",
    "        \"\"\"\n",
    "        for state in states:\n",
    "            self.G[state] = np.random.uniform(low=-1.0, high=-0.1)\n",
    "\n",
    "    def updateStateHistory(self):\n",
    "        \"\"\"changes the current state of the agent.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def chooseAction(self):\n",
    "        \"\"\"controls what action the agent will take.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def learn(self):\n",
    "        \"\"\"decision agent takes\"\"\"\n",
    "        target = 0  # we only learn when we beat the maze\n",
    "\n",
    "        # iterate over reversed state and reward pairs starting from that state\n",
    "        # increment target with the reward\n",
    "        for prev, reward in reversed(self.stateHistory):\n",
    "            self.G[prev] = self.G[prev] + self.alpha * (target - self.G[prev])\n",
    "            target += reward\n",
    "\n",
    "        # zero out agents memory for the next episode\n",
    "        self.stateHistory = []\n",
    "\n",
    "\n",
    "# 6*6 maze, Update moves, check if game over, get the state, get rewards, print maze\n",
    "# robot position 2\n",
    "# class Environment:\n",
    "#     def __init__(self, state):\n",
    "#         self.state = None\n",
    "\n",
    "#     def createMaze(self, noofrows=6, noofcolumns=6):\n",
    "#         maze = np.zeros(shape=(noofrows, noofcolumns))\n",
    "#         global maze\n",
    "\n",
    "#     def printMaze(self):\n",
    "#         return maze\n",
    "\n",
    "#     def updateMove(self, rowindice, columnindice, maxmoves=[0]):\n",
    "#         position = np.put(maze, [rowindice, columnindice], 1)\n",
    "#         maxmoves[0] += 1\n",
    "#         global maxmoves\n",
    "#         global rowindice, columnindice\n",
    "#         return position\n",
    "\n",
    "#     def gameOver(self):\n",
    "#         if maxmoves >= 10:\n",
    "#             print(\"Game Over\")\n",
    "#         else:\n",
    "#             print(\"Still have\")\n",
    "#         return maxmoves\n",
    "\n",
    "#     def getReward(self):  # can't think of a way to update\n",
    "#         if position != 1 | maxmoves < 10:\n",
    "#             continue\n",
    "#         else:\n",
    "#             StopIteration()\n",
    "\n",
    "#     def getState(self):\n",
    "#         current_state = []\n",
    "#         return current_state.append(rowindice, columnindice)\n",
    "\n",
    "#     def getState(self):\n",
    "#         return self.state\n",
    "\n",
    "# some similar components to the one above issue contextuatizing the maze and getting ahead of myself.\n",
    "class Maze:\n",
    "    \"\"\"An RL environment for a robot in a 6 row and 6 column matrix trying to find its way to the objective.\n",
    "    obstacles are labelled 1, robot position identity is 2 at the position 0,0 in a tuple.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(object):\n",
    "        self.maze = np.zeros(shape=(6, 6))\n",
    "        self.maze[5, :5] = 1  # np.put(self.maze, [5, :5], 1) wall\n",
    "        self.maze[:4, 5] = 1  # np.put(self.maze, [:4, 5], 1) wall\n",
    "        self.maze[2, 2:] = 1  # np.put(self.maze, [2, 2:], 1) wall\n",
    "        self.maze[3, 2] = 1  # np.put(self.maze, [3, 2], 1) wall\n",
    "        self.maze[0, 0] = 2  # np.put(self.maze, [0,0], 2) robot\n",
    "        self.robotPosition = (0, 0)  # actual position at start\n",
    "\n",
    "    def printMaze(self):\n",
    "        \"\"\"for debugging purposes. Let's you see the current state of the maze\"\"\"\n",
    "        pass\n",
    "\n",
    "    def isAllowedtoMove(self, state, action):\n",
    "        \"\"\"Determining if a move is allowed.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        state :\n",
    "            \n",
    "        action :\n",
    "            \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "\n",
    "        \n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def updateMaze(self, action):\n",
    "        \"\"\"Updates the maze give the action taken.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        action :\n",
    "            \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "\n",
    "        \n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def isGameOver(self):\n",
    "        \"\"\"Allows the game to end at some point.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def getState(self):\n",
    "        \"\"\"Figuring out the current state of the system.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def giveReward(self, state):\n",
    "        \"\"\"Issues reward to the agent based on state of the system.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        state :\n",
    "            \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "\n",
    "        \n",
    "        \"\"\"\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abf7619e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#format code\r\n",
      "black *.py \r\n",
      "/bin/sh: 1: black: not found\r\n",
      "make: *** [Makefile:30: format] Error 127\r\n"
     ]
    }
   ],
   "source": [
    "!make format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001acafa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5 (default, Sep  4 2020, 07:30:14) \n[GCC 7.3.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "4eae578b6ad286c4a191e6a1576aef0985e51e240c31d8d3356995ce2de78ceb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
